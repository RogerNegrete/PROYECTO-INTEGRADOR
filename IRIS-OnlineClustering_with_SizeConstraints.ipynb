{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "FINAL CODIGO:"
      ],
      "metadata": {
        "id": "a113594tsyFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class OnlineKMeansCapacitado:\n",
        "    def __init__(self, k, capacities):\n",
        "        self.k = k\n",
        "        self.capacities = capacities[:]\n",
        "        self.remaining = capacities[:]\n",
        "        self.centers = []\n",
        "        self.counts = []\n",
        "\n",
        "    def partial_fit(self, x):\n",
        "        x = np.asarray(x).astype(float)\n",
        "\n",
        "        if len(self.centers) < self.k:\n",
        "            self.centers.append(x.copy())\n",
        "            self.counts.append(1)\n",
        "            self.remaining[len(self.centers) - 1] -= 1\n",
        "            return len(self.centers) - 1\n",
        "\n",
        "        distances = []\n",
        "        for i, c in enumerate(self.centers):\n",
        "            if self.remaining[i] > 0:\n",
        "                distances.append(np.linalg.norm(x - c))\n",
        "            else:\n",
        "                distances.append(np.inf)\n",
        "\n",
        "        idx = int(np.argmin(distances))\n",
        "\n",
        "        self.counts[idx] += 1\n",
        "        self.remaining[idx] -= 1\n",
        "\n",
        "        eta = 1.0 / self.counts[idx]\n",
        "        self.centers[idx] = (1.0 - eta) * self.centers[idx] + eta * x\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "wI55rAp1Ze9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dunn_index(X, labels):\n",
        "    clusters = np.unique(labels)\n",
        "\n",
        "    if len(clusters) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # distancia mínima entre clusters\n",
        "    inter_cluster_dist = np.inf\n",
        "    for i in clusters:\n",
        "        for j in clusters:\n",
        "            if i >= j:\n",
        "                continue\n",
        "            dist = np.min([\n",
        "                np.linalg.norm(x - y)\n",
        "                for x in X[labels == i]\n",
        "                for y in X[labels == j]\n",
        "            ])\n",
        "            inter_cluster_dist = min(inter_cluster_dist, dist)\n",
        "\n",
        "    # diámetro máximo intra-cluster\n",
        "    intra_cluster_dist = 0\n",
        "    for i in clusters:\n",
        "        points = X[labels == i]\n",
        "        if len(points) > 1:\n",
        "            dist = np.max([\n",
        "                np.linalg.norm(x - y)\n",
        "                for x in points\n",
        "                for y in points\n",
        "            ])\n",
        "            intra_cluster_dist = max(intra_cluster_dist, dist)\n",
        "\n",
        "    if intra_cluster_dist == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return inter_cluster_dist / intra_cluster_dist"
      ],
      "metadata": {
        "id": "XdLK4-tOZfqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score,\n",
        "    adjusted_mutual_info_score\n",
        ")\n",
        "\n",
        "def dunn_index(X, labels):\n",
        "    clusters = np.unique(labels)\n",
        "\n",
        "    if len(clusters) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # distancia mínima entre clusters\n",
        "    inter_cluster_dist = np.inf\n",
        "    for i in clusters:\n",
        "        for j in clusters:\n",
        "            if i >= j:\n",
        "                continue\n",
        "            dist = np.min([\n",
        "                np.linalg.norm(x - y)\n",
        "                for x in X[labels == i]\n",
        "                for y in X[labels == j]\n",
        "            ])\n",
        "            inter_cluster_dist = min(inter_cluster_dist, dist)\n",
        "\n",
        "    # diámetro máximo intra-cluster\n",
        "    intra_cluster_dist = 0\n",
        "    for i in clusters:\n",
        "        points = X[labels == i]\n",
        "        if len(points) > 1:\n",
        "            dist = np.max([\n",
        "                np.linalg.norm(x - y)\n",
        "                for x in points\n",
        "                for y in points\n",
        "            ])\n",
        "            intra_cluster_dist = max(intra_cluster_dist, dist)\n",
        "\n",
        "    if intra_cluster_dist == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return inter_cluster_dist / intra_cluster_dist\n",
        "\n",
        "# Cargar Iris\n",
        "X, y_true = load_iris(return_X_y=True)\n",
        "\n",
        "# ===== ALEATORIZACIÓN DE DATOS =====\n",
        "X, y_true = shuffle(X, y_true)\n",
        "\n",
        "# Parámetros dados\n",
        "k = 3\n",
        "capacities = [50, 50, 50]\n",
        "\n",
        "# ===== NUEVA MÉTRICA THRESHOLD =====\n",
        "threshold = 0.85\n",
        "\n",
        "# ===== VALIDACIÓN DE ENTRADA =====\n",
        "if sum(capacities) != X.shape[0]:\n",
        "    raise ValueError(\n",
        "        \"La suma de los tamaños de clusters no coincide con el total \"\n",
        "        \"de instancias del dataset.\"\n",
        "    )\n",
        "\n",
        "# ===== MODELO =====\n",
        "model = OnlineKMeansCapacitado(k, capacities)\n",
        "\n",
        "# Streaming ONLINE + Normalización L2 por punto\n",
        "labels = []\n",
        "X_norm = []\n",
        "distancias = []\n",
        "\n",
        "for x in X:\n",
        "    norm = np.linalg.norm(x)\n",
        "    x_norm = x / norm if norm > 0 else x\n",
        "    X_norm.append(x_norm)\n",
        "\n",
        "    label = model.partial_fit(x_norm)\n",
        "    labels.append(label)\n",
        "\n",
        "    # Distancia y threshold antes de guardar\n",
        "    centroide = model.centers[label]\n",
        "    dist = np.linalg.norm(x_norm - centroide)\n",
        "    distancias.append(dist)\n",
        "\n",
        "X_norm = np.array(X_norm)\n",
        "labels = np.array(labels)\n",
        "distancias = np.array(distancias)\n",
        "\n",
        "# ===== Métricas =====\n",
        "silhouette = silhouette_score(X_norm, labels)\n",
        "dunn = dunn_index(X_norm, labels)\n",
        "\n",
        "ari = adjusted_rand_score(y_true, labels)\n",
        "nmi = normalized_mutual_info_score(y_true, labels)\n",
        "ami = adjusted_mutual_info_score(y_true, labels)\n",
        "\n",
        "# ===== Métrica Threshold =====\n",
        "threshold_ratio = float(np.mean(distancias <= threshold))\n",
        "\n",
        "# Resultados\n",
        "print(\"Tamaños de clusters:\", np.bincount(labels))\n",
        "print(\"\\nValidación interna:\")\n",
        "print(\"  Silhouette:\", round(silhouette, 4))\n",
        "print(\"  Dunn index:\", round(dunn, 4))\n",
        "\n",
        "print(\"\\nValidación externa:\")\n",
        "print(\"  ARI:\", round(ari, 4))\n",
        "print(\"  NMI:\", round(nmi, 4))\n",
        "print(\"  AMI:\", round(ami, 4))\n",
        "\n",
        "print(\"\\nNueva métrica threshold:\")\n",
        "print(\"  Threshold (<=):\", threshold)\n",
        "print(\"  Proporción dentro del threshold:\", round(threshold_ratio, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AScH0Qssx08",
        "outputId": "c46a6748-ab23-4b38-a5b0-9c7a4ac1f5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaños de clusters: [50 50 50]\n",
            "\n",
            "Validación interna:\n",
            "  Silhouette: 0.0932\n",
            "  Dunn index: 0.0\n",
            "\n",
            "Validación externa:\n",
            "  ARI: 0.2422\n",
            "  NMI: 0.268\n",
            "  AMI: 0.2588\n",
            "\n",
            "Nueva métrica threshold:\n",
            "  Threshold (<=): 0.85\n",
            "  Proporción dentro del threshold: 1.0\n"
          ]
        }
      ]
    }
  ]
}